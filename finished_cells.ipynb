{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuviettran/demo-github/blob/main/finished_cells.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MESMMdcWZgt5",
        "outputId": "580ae8a5-49ad-4dee-e013-48ffe53fd2a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PathoNet'...\n",
            "remote: Enumerating objects: 272, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 272 (delta 18), reused 13 (delta 13), pack-reused 246 (from 1)\u001b[K\n",
            "Receiving objects: 100% (272/272), 3.18 MiB | 8.00 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n",
            "/content/PathoNet\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6.1)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2026.1.14)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6.1)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2026.1.14)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "# Clone mã nguồn từ GitHub\n",
        "!git clone https://github.com/SHIDCenter/PathoNet.git\n",
        "%cd PathoNet\n",
        "\n",
        "# Cài đặt các thư viện cần thiết\n",
        "!pip install opencv-python scikit-image matplotlib\n",
        "!pip install opencv-python scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxZqF_CPhX6l",
        "outputId": "4a442c1e-d6e3-444a-f858-c79d413c1f28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Đường dẫn gốc trên Drive của bạn\n",
        "drive_path = '/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images'\n",
        "\n",
        "# Tạo liên kết đến thư mục train và test\n",
        "train_src = os.path.join(drive_path, 'train256')\n",
        "test_src = os.path.join(drive_path, 'test256')\n",
        "\n",
        "print(f\"Kiểm tra thư mục Train: {os.path.exists(train_src)}\")\n",
        "print(f\"Kiểm tra thư mục Test: {os.path.exists(test_src)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYQI-sTeissm",
        "outputId": "f2e00b89-6e41-4bb4-d328-ea56b471db59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kiểm tra thư mục Train: True\n",
            "Kiểm tra thư mục Test: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Hạ cấp các thư viện về phiên bản PathoNet cần\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install keras==2.12.0\n",
        "!pip install scipy==1.2.1\n",
        "!pip install opencv-python\n",
        "\n",
        "# 2. Sửa lỗi import trong mã nguồn (PathoNet/models.py)\n",
        "import os\n",
        "file_path = \"/content/PathoNet/PathoNet/models.py\"\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    # Thay thế đường dẫn import cũ bằng đường dẫn mới của TF 2.x\n",
        "    content = content.replace(\"from keras.utils.layer_utils import get_source_inputs\",\n",
        "                              \"from tensorflow.keras.utils import get_source_inputs\")\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"Đã sửa lỗi import trong models.py thành công!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8eznkDRkCxj",
        "outputId": "4cc15d0f-491f-4b84-f879-7f64b938f2ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.12.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.12.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.10.0\n",
            "    Uninstalling keras-3.10.0:\n",
            "      Successfully uninstalled keras-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-hub 0.21.1 requires keras>=3.5, but you have keras 2.12.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n",
            "Collecting scipy==1.2.1\n",
            "  Downloading scipy-1.2.1.tar.gz (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras scipy opencv-python pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7S8cqFwlFcy",
        "outputId": "981b0f96-2fcc-4ac6-b193-240493e5e793"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.13.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.18.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Downloading keras-3.13.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "Successfully installed keras-3.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Sửa lỗi import Keras trong models.py\n",
        "file_models = \"/content/PathoNet/PathoNet/models.py\"\n",
        "if os.path.exists(file_models):\n",
        "    with open(file_models, 'r') as f:\n",
        "        content = f.read()\n",
        "    content = content.replace(\"from keras.utils.layer_utils import get_source_inputs\",\n",
        "                              \"from tensorflow.keras.utils import get_source_inputs\")\n",
        "    with open(file_models, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Đã sửa models.py\")\n",
        "\n",
        "# 2. Sửa lỗi scipy.misc trong train.py\n",
        "file_train = \"/content/PathoNet/PathoNet/train.py\"\n",
        "if os.path.exists(file_train):\n",
        "    with open(file_train, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    with open(file_train, 'w') as f:\n",
        "        for line in lines:\n",
        "            if \"from scipy import misc\" in line:\n",
        "                f.write(\"from PIL import Image\\nimport numpy as np\\n\")\n",
        "            elif \"misc.imread\" in line:\n",
        "                # Thay thế misc.imread bằng Pillow\n",
        "                line = line.replace(\"misc.imread\", \"np.array(Image.open\")\n",
        "                f.write(line)\n",
        "            else:\n",
        "                f.write(line)\n",
        "    print(\"✓ Đã sửa train.py (thay scipy bằng Pillow)\")"
      ],
      "metadata": {
        "id": "GCo6o_sllQ03"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Số lượng GPU khả dụng:\", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdwhRR14lZCi",
        "outputId": "c43bf99e-ae04-4dea-b6d7-6b6d7e187ee5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng GPU khả dụng: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "files_to_fix = [\n",
        "    \"/content/PathoNet/PathoNet/models.py\",\n",
        "    \"/content/PathoNet/PathoNet/train.py\"\n",
        "]\n",
        "\n",
        "for file_path in files_to_fix:\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Sửa các lỗi import Keras phổ biến\n",
        "        content = content.replace(\"from keras.utils.layer_utils import get_source_inputs\", \"from tensorflow.keras.utils import get_source_inputs\")\n",
        "        content = content.replace(\"from keras.utils.data_utils import get_file\", \"from tensorflow.keras.utils import get_file\")\n",
        "        content = content.replace(\"import keras.backend as K\", \"from tensorflow.keras import backend as K\")\n",
        "\n",
        "        # Sửa lỗi scipy.misc đã bị xóa\n",
        "        if \"from scipy import misc\" in content:\n",
        "            content = content.replace(\"from scipy import misc\", \"from PIL import Image\\nimport numpy as np\")\n",
        "            content = content.replace(\"misc.imread\", \"np.array(Image.open\")\n",
        "\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(content)\n",
        "        print(f\"✓ Đã sửa file: {file_path}\")"
      ],
      "metadata": {
        "id": "BgXu82cNl7Q9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Định nghĩa cấu hình trỏ vào thư mục ảnh đã crop 256x256 trên Drive\n",
        "config = {\n",
        "    \"train_path\": \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/train256\",\n",
        "    \"test_path\": \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\",\n",
        "    \"save_path\": \"/content/drive/MyDrive/PathoNet_Results\", # Nơi lưu mô hình sau khi train\n",
        "    \"batch_size\": 16,\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 1e-4,\n",
        "    \"model_name\": \"PathoNet\"\n",
        "}\n",
        "\n",
        "# Lưu file config\n",
        "with open('/content/PathoNet/PathoNet/my_train_config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "# Tạo thư mục lưu kết quả trên Drive để không bị mất khi đóng Colab\n",
        "!mkdir -p \"/content/drive/MyDrive/PathoNet_Results\"\n",
        "\n",
        "print(\"✓ Đã tạo file cấu hình thành công!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "vWrGgTOBnLPc",
        "outputId": "0f232321-b8f6-470d-f422-dc7c710e81f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/PathoNet/PathoNet/my_train_config.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1860161011.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Lưu file config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/PathoNet/PathoNet/my_train_config.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/PathoNet/PathoNet/my_train_config.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/train.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Thay đổi đuôi .hdf5 thành .weights.h5 để phù hợp với Keras mới\n",
        "    old_ext = \".hdf5\"\n",
        "    new_ext = \".weights.h5\"\n",
        "\n",
        "    if old_ext in content:\n",
        "        content = content.replace(old_ext, new_ext)\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(content)\n",
        "        print(f\"✓ Đã cập nhật định dạng checkpoint trong {file_path}\")\n",
        "    else:\n",
        "        print(\"! Không tìm thấy định dạng .hdf5 hoặc file đã được sửa.\")"
      ],
      "metadata": {
        "id": "74EhWKA-nwh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/models.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Sửa lỗi 'input =' thành 'inputs =' và 'output =' thành 'outputs ='\n",
        "    # Sử dụng replace với khoảng trắng để tránh đổi nhầm các biến khác\n",
        "    content = content.replace(\"Model(input =\", \"Model(inputs =\")\n",
        "    content = content.replace(\"Model(output =\", \"Model(outputs =\")\n",
        "\n",
        "    # Một số trường hợp không có khoảng trắng\n",
        "    content = content.replace(\"Model(input=\", \"Model(inputs=\")\n",
        "    content = content.replace(\"Model(output=\", \"Model(outputs=\")\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(f\"✓ Đã sửa lỗi tham số Model trong {file_path}\")\n",
        "else:\n",
        "    print(\"! Không tìm thấy file models.py.\")"
      ],
      "metadata": {
        "id": "EioZDk99oUwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/models.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Sửa lỗi đồng bộ: input -> inputs VÀ output -> outputs\n",
        "    # Chúng ta dùng replace chính xác để tránh dính lỗi lặp lại\n",
        "    content = content.replace(\"input =\", \"inputs =\").replace(\"input=\", \"inputs=\")\n",
        "    content = content.replace(\"output =\", \"outputs =\").replace(\"output=\", \"outputs=\")\n",
        "\n",
        "    # Sửa lỗi thừa chữ s nếu đã lỡ chạy script trước đó (inputs s = ...)\n",
        "    content = content.replace(\"inputss\", \"inputs\")\n",
        "    content = content.replace(\"outputss\", \"outputs\")\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(f\"✓ Đã sửa lỗi tham số Model (inputs/outputs) trong {file_path}\")"
      ],
      "metadata": {
        "id": "zFArvsblo9XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"/content/PathoNet/PathoNet/train.py\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Đảm bảo dùng Optimizer từ tensorflow.keras\n",
        "content = content.replace(\"from keras.optimizers import Adam\", \"from tensorflow.keras.optimizers import Adam\")\n",
        "# Sửa lỗi phổ biến khi gọi Adam trong TF 2.x/3.x\n",
        "content = content.replace(\"Adam(lr=\", \"Adam(learning_rate=\")\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Đã cập nhật Optimizer chuẩn TF 2.x/3.x\")"
      ],
      "metadata": {
        "id": "Nf7mmvPzp4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Đảm bảo thư mục lưu kết quả tồn tại\n",
        "log_dir = \"/content/drive/MyDrive/PathoNet_Results\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "config = {\n",
        "    \"trainDataPath\": \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/train256\",\n",
        "    \"testDataPath\": \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\",\n",
        "    \"logPath\": log_dir,\n",
        "    \"model\": \"PathoNet\",\n",
        "    \"inputShape\": [256, 256, 3],\n",
        "    \"classes\": 3,\n",
        "    \"batchSize\": 16,\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 0.0001,\n",
        "    \"pretrainedModel\": \"\"\n",
        "}\n",
        "\n",
        "with open('/content/PathoNet/PathoNet/my_train_config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "print(\"✓ Đã cập nhật file cấu hình với các khóa chuẩn (trainDataPath, logPath...)\")"
      ],
      "metadata": {
        "id": "e_moBHcNqiiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/train256\" | head -n 5"
      ],
      "metadata": {
        "id": "GF8q32QIqp6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"/content/PathoNet/PathoNet/train.py\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        # Đảm bảo logic đọc mọi file có đuôi .jpg thay vì chỉ lọc theo prefix 'p'\n",
        "        if \"if '.jpg' in f\" in line:\n",
        "            f.write(line) # Giữ nguyên nếu đã là lọc đuôi file chung\n",
        "        else:\n",
        "            f.write(line)"
      ],
      "metadata": {
        "id": "UW0qknOerL5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/train.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Thay thế fit_generator bằng fit\n",
        "    content = content.replace(\"model.fit_generator\", \"model.fit\")\n",
        "\n",
        "    # Một số phiên bản cũ có thể dùng validation_data=testDataLoader.generator()\n",
        "    # Nếu có tham số 'steps_per_epoch', hàm 'fit' vẫn giữ nguyên nên không cần đổi\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Đã cập nhật model.fit_generator thành model.fit\")"
      ],
      "metadata": {
        "id": "RERU_bZqrcVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/train.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # 1. Đổi 'generator=trainDataLoader.generator()' thành 'trainDataLoader.generator()'\n",
        "    content = content.replace(\"generator=trainDataLoader.generator()\", \"trainDataLoader.generator()\")\n",
        "\n",
        "    # 2. Đổi 'validation_data=testDataLoader.generator()' (nếu có) để bỏ từ khóa 'generator'\n",
        "    # Keras nhận diện generator tự động thông qua tham số x (vị trí đầu tiên)\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Đã sửa tham số truyền vào hàm fit().\")"
      ],
      "metadata": {
        "id": "JyS2o4U6ryyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def generate_npy_labels(folder_path):\n",
        "    # Lấy danh sách các file ảnh để đảm bảo tạo nhãn tương ứng\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
        "    print(f\"Đang xử lý {len(image_files)} tệp tại: {folder_path}\")\n",
        "\n",
        "    for img_name in image_files:\n",
        "        json_path = os.path.join(folder_path, img_name.replace(\".jpg\", \".json\"))\n",
        "        npy_path = os.path.join(folder_path, img_name.replace(\".jpg\", \".npy\"))\n",
        "\n",
        "        # Tạo mask trống 256x256x3 (cho 3 loại tế bào)\n",
        "        mask = np.zeros((256, 256, 3), dtype=np.float32)\n",
        "\n",
        "        if os.path.exists(json_path):\n",
        "            with open(json_path, 'r') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    for item in data:\n",
        "                        x, y, label = int(item['x']), int(item['y']), int(item['label'])\n",
        "                        # Giới hạn tọa độ trong khung 256x256\n",
        "                        if 0 <= x < 256 and 0 <= y < 256:\n",
        "                            # Label 1: Positive, 2: Negative, 3: TILs\n",
        "                            if 1 <= label <= 3:\n",
        "                                mask[y, x, label-1] = 1.0\n",
        "                except:\n",
        "                    pass # Bỏ qua nếu file JSON lỗi hoặc trống\n",
        "\n",
        "        # Lưu dưới dạng .npy để PathoNet có thể đọc\n",
        "        np.save(npy_path, mask)\n",
        "\n",
        "# Thực thi cho cả thư mục Train và Test\n",
        "train_dir = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/train256\"\n",
        "test_dir = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\"\n",
        "\n",
        "generate_npy_labels(train_dir)\n",
        "generate_npy_labels(test_dir)\n",
        "print(\"✓ Đã tạo xong toàn bộ tệp .npy!\")"
      ],
      "metadata": {
        "id": "z-pZC0battuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/PathoNet/PathoNet/utils.py\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Thay thế np.float thành float (kiểu builtin an toàn nhất)\n",
        "    # Sửa cả trường hợp np.int nếu có để tránh lỗi dây chuyền\n",
        "    content = content.replace(\"np.float(\", \"float(\")\n",
        "    content = content.replace(\"np.int(\", \"int(\")\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Đã sửa lỗi np.float trong utils.py\")"
      ],
      "metadata": {
        "id": "Xo6Psp36uS6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PathoNet/PathoNet/\n",
        "!python train.py --configPath \"my_train_config.json\""
      ],
      "metadata": {
        "id": "9-RrA4TxopHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/PathoNet/PathoNet')\n",
        "print(f\"Thư mục hiện tại: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "hRFnjOiSnKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "content = \"\"\"\n",
        "import numpy as np\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed\n",
        "from scipy import ndimage\n",
        "import cv2\n",
        "\n",
        "class Pipeline:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.thresholds = [0.1, 0.1, 0.1] # Ngưỡng cho 3 loại tế bào\n",
        "        self.minDistance = 5\n",
        "\n",
        "    def predict(self, img):\n",
        "        # 1. Chuẩn hóa ảnh đầu vào\n",
        "        img_input = np.expand_dims(img, axis=0) / 255.0\n",
        "\n",
        "        # 2. Chạy mô hình PathoNet để lấy Heatmap\n",
        "        preds = self.model.predict(img_input, verbose=0)[0]\n",
        "\n",
        "        # 3. Hậu xử lý đếm tế bào\n",
        "        counts = []\n",
        "        for i in range(3):\n",
        "            heatmap = preds[:, :, i]\n",
        "            # Sử dụng peak_local_max không có tham số 'indices' để tránh lỗi\n",
        "            coords = peak_local_max(heatmap, min_distance=self.minDistance,\n",
        "                                   threshold_abs=self.thresholds[i])\n",
        "            counts.append(len(coords))\n",
        "\n",
        "        return counts\n",
        "\"\"\"\n",
        "\n",
        "with open(\"pipeline.py\", 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Đã cài đặt Pipeline mới tương thích hoàn toàn với Python 3.12.\")"
      ],
      "metadata": {
        "id": "6BILYgvcGbfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from models import PathoNet\n",
        "from pipeline import Pipeline\n",
        "\n",
        "# --- ĐƯỜNG DẪN ---\n",
        "weights_path = \"/content/drive/MyDrive/PathoNet_Results/PathoNet_adam_0.0001_2026-01-26_06-40-51/Checkpoint-30-0.21.weights.h5\"\n",
        "input_path = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\"\n",
        "\n",
        "# 1. Khởi tạo\n",
        "print(\"Đang tải mô hình...\")\n",
        "model = PathoNet()\n",
        "model.load_weights(weights_path)\n",
        "pipe = Pipeline(model)\n",
        "\n",
        "# 2. Quét danh sách ảnh\n",
        "image_files = [f for f in os.listdir(input_path) if f.lower().endswith(('.jpg', '.png'))]\n",
        "image_files.sort()\n",
        "\n",
        "print(f\"--- Đang phân tích {len(image_files)} ảnh ---\")\n",
        "\n",
        "# 3. Thực thi (thử nghiệm 10 ảnh đầu)\n",
        "for filename in image_files[:10]:\n",
        "    try:\n",
        "        img = imageio.imread(os.path.join(input_path, filename))\n",
        "        # Kiến trúc Residual Dilated Inception giúp nhận diện tế bào đa quy mô\n",
        "        counts = pipe.predict(img)\n",
        "        print(f\"✓ {filename} -> Ki-67(+): {counts[0]}, Ki-67(-): {counts[1]}, TILs: {counts[2]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Lỗi tại {filename}: {e}\")"
      ],
      "metadata": {
        "id": "bbEc6-o9Gl28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "\n",
        "# Tạo danh sách để lưu kết quả\n",
        "results_list = []\n",
        "\n",
        "print(f\"--- Đang bắt đầu xử lý tổng cộng {len(image_files)} ảnh ---\")\n",
        "\n",
        "for i, filename in enumerate(image_files):\n",
        "    try:\n",
        "        img_path = os.path.join(input_path, filename)\n",
        "        img = imageio.imread(img_path)\n",
        "\n",
        "        # Gọi hàm dự đoán từ Pipeline đã vá lỗi\n",
        "        counts = pipe.predict(img)\n",
        "\n",
        "        # Lưu thông tin vào dictionary\n",
        "        results_list.append({\n",
        "            'Image_Name': filename,\n",
        "            'Ki67_Positive': counts[0],\n",
        "            'Ki67_Negative': counts[1],\n",
        "            'TILs': counts[2],\n",
        "            'Total_Cells': sum(counts)\n",
        "        })\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Đã xử lý: {i + 1}/{len(image_files)} ảnh...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Bỏ qua ảnh {filename} do lỗi: {e}\")\n",
        "\n",
        "# Chuyển thành DataFrame và lưu file\n",
        "df = pd.DataFrame(results_list)\n",
        "output_file = \"/content/drive/MyDrive/PathoNet_Final_Report.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"\\n✅ XONG! Báo cáo đã được lưu tại: {output_file}\")\n",
        "df.head() # Hiển thị 5 dòng đầu tiên để kiểm tra"
      ],
      "metadata": {
        "id": "kGlmTu3JJ3NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Tính toán Ki-67 Index (%) cho từng ảnh\n",
        "# Tránh chia cho 0 nếu ảnh không có tế bào ung thư\n",
        "df['Ki67_Index'] = (df['Ki67_Positive'] / (df['Ki67_Positive'] + df['Ki67_Negative'])) * 100\n",
        "df['Ki67_Index'] = df['Ki67_Index'].fillna(0) # Thay thế NaN bằng 0\n",
        "\n",
        "# 2. Thiết lập giao diện biểu đồ\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Biểu đồ 1: Phân bố Chỉ số Ki-67\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['Ki67_Index'], bins=20, kde=True, color='brown')\n",
        "plt.title('Phân bố Chỉ số Ki-67 Index (%)')\n",
        "plt.xlabel('Ki-67 Index (%)')\n",
        "plt.ylabel('Số lượng mẫu ảnh')\n",
        "\n",
        "# Biểu đồ 2: Tương quan giữa Ki-67(+) và TILs\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.scatterplot(data=df, x='Ki67_Positive', y='TILs', hue='Ki67_Index', palette='viridis')\n",
        "plt.title('Tương quan giữa Tế bào Ki-67(+) và TILs')\n",
        "plt.xlabel('Số lượng Ki-67 Positive')\n",
        "plt.ylabel('Số lượng TILs')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# In ra các chỉ số thống kê cơ bản\n",
        "print(f\"--- THỐNG KÊ TỔNG QUÁT (700 mẫu) ---\")\n",
        "print(f\"Ki-67 Index trung bình: {df['Ki67_Index'].mean():.2f}%\")\n",
        "print(f\"Ảnh có Ki-67 cao nhất: {df['Ki67_Index'].max():.2f}%\")\n",
        "print(f\"Tổng số tế bào đã đếm được: {df['Total_Cells'].sum():,.0f}\")"
      ],
      "metadata": {
        "id": "2Iry2iI5KZH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from skimage.feature import peak_local_max\n",
        "\n",
        "# 1. Tạo thư mục lưu ảnh minh họa trên Drive\n",
        "save_dir = \"/content/drive/MyDrive/PathoNet_Top_Samples\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# 2. Lấy danh sách 5 ảnh có Ki-67 Index cao nhất từ kết quả trước đó\n",
        "top_5_df = df.sort_values(by='Ki67_Index', ascending=False).head(5)\n",
        "\n",
        "print(f\"--- Đang vẽ kết quả cho 5 mẫu tiêu biểu nhất ---\")\n",
        "\n",
        "for idx, row in top_5_df.iterrows():\n",
        "    filename = row['Image_Name']\n",
        "    img_path = os.path.join(input_path, filename)\n",
        "\n",
        "    # Đọc ảnh gốc\n",
        "    img = imageio.imread(img_path)\n",
        "\n",
        "    # Tiền xử lý và dự đoán Heatmap\n",
        "    img_input = np.expand_dims(img, axis=0) / 255.0\n",
        "    preds = model.predict(img_input, verbose=0)[0]\n",
        "\n",
        "    # Khởi tạo bản vẽ\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Cấu hình màu sắc và nhãn\n",
        "    colors = ['red', 'lime', 'blue']\n",
        "    labels = ['Ki-67(+)', 'Ki-67(-)', 'TILs']\n",
        "\n",
        "    for i in range(3):\n",
        "        heatmap = preds[:, :, i]\n",
        "        # Tìm tọa độ tâm tế bào (đã fix lỗi indices)\n",
        "        coords = peak_local_max(heatmap, min_distance=5, threshold_abs=0.1)\n",
        "\n",
        "        if len(coords) > 0:\n",
        "            plt.scatter(coords[:, 1], coords[:, 0], c=colors[i], s=40,\n",
        "                        edgecolors='white', linewidth=0.5, label=f\"{labels[i]}: {len(coords)}\")\n",
        "\n",
        "    plt.title(f\"Mẫu: {filename} | Chỉ số Ki-67: {row['Ki67_Index']:.2f}%\", fontsize=15)\n",
        "    plt.legend(loc='upper right', fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Lưu ảnh vào Google Drive\n",
        "    save_path = os.path.join(save_dir, f\"Analysis_{filename}\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"✓ Đã lưu kết quả phân tích: {save_path}\")\n",
        "\n",
        "print(f\"\\n Lưu vào Google Drive thư mục 'PathoNet_Top_Samples' để lấy ảnh báo cáo.\")"
      ],
      "metadata": {
        "id": "9mbIM0HQL5bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import os\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from scipy.spatial.distance import cdist\n",
        "\n",
        "# # --- CẤU HÌNH ĐƯỜNG DẪN ---\n",
        "# json_path = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images\\test256\" # Sửa đường dẫn này\n",
        "\n",
        "# def get_gt_from_json(json_file):\n",
        "#     \"\"\"\n",
        "#     Hàm này trích xuất tọa độ từ JSON.\n",
        "#     Lưu ý: Cấu trúc này có thể cần điều chỉnh tùy theo file JSON của bạn.\n",
        "#     \"\"\"\n",
        "#     with open(json_file, 'r') as f:\n",
        "#         data = json.load(f)\n",
        "\n",
        "#     # Giả sử JSON là danh sách các điểm: [{\"x\": 10, \"y\": 20, \"label\": 1}, ...]\n",
        "#     # Ki-67(+) thường có label là 1 hoặc 0 tùy bộ dữ liệu\n",
        "#     pos_coords = []\n",
        "#     for point in data:\n",
        "#         if 'x' in point and 'y' in point:\n",
        "#             pos_coords.append([point['y'], point['x']]) # Đổi sang (row, col)\n",
        "#     return np.array(pos_coords)\n",
        "\n",
        "# results_metrics = []\n",
        "# threshold = 15 # Khoảng cách tối đa (pixels) để coi là đếm đúng\n",
        "\n",
        "# print(\"--- Đang tính toán độ chính xác dựa trên Ground Truth (JSON) ---\")\n",
        "\n",
        "# for filename in image_files[:50]: # Thử nghiệm với 50 ảnh đầu tiên\n",
        "#     json_name = filename.rsplit('.', 1)[0] + '.json'\n",
        "#     full_json_path = os.path.join(json_path, json_name)\n",
        "\n",
        "#     if os.path.exists(full_json_path):\n",
        "#         # 1. Lấy tọa độ thực tế (GT)\n",
        "#         gt_coords = get_gt_from_json(full_json_path)\n",
        "\n",
        "#         # 2. Lấy tọa độ dự đoán (AI) cho lớp Ki-67(+)\n",
        "#         img = imageio.imread(os.path.join(input_path, filename))\n",
        "#         img_input = np.expand_dims(img, axis=0) / 255.0\n",
        "#         preds = model.predict(img_input, verbose=0)[0]\n",
        "#         pred_coords = peak_local_max(preds[:,:,0], min_distance=5, threshold_abs=0.1)\n",
        "\n",
        "#         # 3. So khớp tọa độ\n",
        "#         if len(gt_coords) > 0 and len(pred_coords) > 0:\n",
        "#             dists = cdist(pred_coords, gt_coords)\n",
        "#             tp = 0\n",
        "#             matched_gt = set()\n",
        "#             for i in range(len(pred_coords)):\n",
        "#                 nearest_gt = np.argmin(dists[i])\n",
        "#                 if dists[i][nearest_gt] < threshold and nearest_gt not in matched_gt:\n",
        "#                     tp += 1\n",
        "#                     matched_gt.add(nearest_gt)\n",
        "\n",
        "#             precision = tp / len(pred_coords)\n",
        "#             recall = tp / len(gt_coords)\n",
        "#             f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "#             results_metrics.append({'F1': f1, 'Precision': precision, 'Recall': recall})\n",
        "\n",
        "# # Tính trung bình cộng\n",
        "# avg_f1 = np.mean([r['F1'] for r in results_metrics])\n",
        "# avg_pre = np.mean([r['Precision'] for r in results_metrics])\n",
        "# avg_rec = np.mean([r['Recall'] for r in results_metrics])\n",
        "\n",
        "# print(f\"\\n KẾT QUẢ ĐÁNH GIÁ (Dựa trên {len(results_metrics)} ảnh):\")\n",
        "# print(f\" F1-Score trung bình: {avg_f1:.4f}\")\n",
        "# print(f\" Precision trung bình: {avg_pre:.4f}\")\n",
        "# print(f\" Recall trung bình: {avg_rec:.4f}\")\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import imageio.v2 as imageio\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# Đường dẫn đến thư mục chứa 3 loại file của bạn\n",
        "data_path = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\"\n",
        "\n",
        "def calculate_f1_from_folder(model, folder_path, limit=50):\n",
        "    all_metrics = []\n",
        "    # Lấy danh sách các file ảnh\n",
        "    images = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
        "\n",
        "    for filename in images[:limit]:\n",
        "        # 1. Dự đoán từ AI\n",
        "        img = imageio.imread(os.path.join(folder_path, filename))\n",
        "        img_input = np.expand_dims(img, axis=0) / 255.0\n",
        "        preds = model.predict(img_input, verbose=0)[0]\n",
        "        # Lấy tọa độ lớp Ki-67(+)\n",
        "        pred_coords = peak_local_max(preds[:,:,0], min_distance=5, threshold_abs=0.1)\n",
        "\n",
        "        # 2. Đọc nhãn chuẩn từ JSON (cùng tên với file ảnh)\n",
        "        json_name = filename.replace('.jpg', '.json')\n",
        "        json_full_path = os.path.join(folder_path, json_name)\n",
        "\n",
        "        if os.path.exists(json_full_path):\n",
        "            with open(json_full_path, 'r') as f:\n",
        "                gt_data = json.load(f)\n",
        "\n",
        "            # Trích xuất tọa độ từ JSON (Lưu ý: kiểm tra key 'points' hoặc 'dots' trong file của bạn)\n",
        "            gt_coords = np.array([[p['y'], p['x']] for p in gt_data if p.get('label') == 1]) # Ví dụ label 1 là Ki67+\n",
        "\n",
        "            if len(gt_coords) > 0 and len(pred_coords) > 0:\n",
        "                # 3. So khớp khoảng cách (Threshold 15 pixels)\n",
        "                dists = cdist(pred_coords, gt_coords)\n",
        "                tp = 0\n",
        "                matched_gt = set()\n",
        "                for i in range(len(pred_coords)):\n",
        "                    nearest = np.argmin(dists[i])\n",
        "                    if dists[i][nearest] < 15 and nearest not in matched_gt:\n",
        "                        tp += 1\n",
        "                        matched_gt.add(nearest)\n",
        "\n",
        "                pre = tp / len(pred_coords)\n",
        "                rec = tp / len(gt_coords)\n",
        "                f1 = 2 * (pre * rec) / (pre + rec) if (pre + rec) > 0 else 0\n",
        "                all_metrics.append({'f1': f1, 'pre': pre, 'rec': rec})\n",
        "\n",
        "    return all_metrics\n",
        "\n",
        "# Chạy đánh giá\n",
        "metrics = calculate_f1_from_folder(model, data_path)\n",
        "print(f\"F1-Score trung bình trên tập Test: {np.mean([m['f1'] for m in metrics]):.4f}\")"
      ],
      "metadata": {
        "id": "RtlMbzqM8ElX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# --- 1. KHAI BÁO LẠI ĐƯỜNG DẪN (Bạn hãy kiểm tra xem đường dẫn này đúng chưa) ---\n",
        "data_path = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\"\n",
        "\n",
        "# --- 2. KIỂM TRA FILE JSON ---\n",
        "try:\n",
        "    # Lấy danh sách các file JSON\n",
        "    json_files = [f for f in os.listdir(data_path) if f.endswith('.json')]\n",
        "\n",
        "    if len(json_files) == 0:\n",
        "        print(f\"❌ Không tìm thấy file .json nào trong: {data_path}\")\n",
        "    else:\n",
        "        sample_json = json_files[0]\n",
        "        full_path = os.path.join(data_path, sample_json)\n",
        "\n",
        "        with open(full_path, 'r') as f:\n",
        "            sample_data = json.load(f)\n",
        "\n",
        "        print(f\"✅ Đã đọc thành công file: {sample_json}\")\n",
        "        print(\"-\" * 30)\n",
        "        print(\"CẤU TRÚC JSON CỦA BẠN:\")\n",
        "        # In ra 1000 ký tự đầu tiên để xem cấu trúc\n",
        "        print(json.dumps(sample_data, indent=2)[:1000])\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Lỗi: {e}\")"
      ],
      "metadata": {
        "id": "vVQP1_j_sNKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import imageio.v2 as imageio\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# Khai báo lại đường dẫn để tránh lỗi NameError\n",
        "data_path = \"/content/drive/MyDrive/SHIDC-B-Ki-67/SHIDC-B-Ki-67/256x256 cropped images/test256\"\n",
        "\n",
        "def get_gt_by_label(json_data, target_label):\n",
        "    \"\"\"Trích xuất tọa độ chuẩn từ JSON theo nhãn cụ thể\"\"\"\n",
        "    coords = []\n",
        "    for item in json_data:\n",
        "        if item.get('label_id') == target_label:\n",
        "            # Lưu ý: JSON thường là (x, y), ảnh xử lý là (row, col) tức (y, x)\n",
        "            coords.append([item['y'], item['x']])\n",
        "    return np.array(coords)\n",
        "\n",
        "def evaluate_accuracy(model, folder_path, num_samples=30):\n",
        "    images = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
        "    results = {1: [], 2: [], 3: []} # Lưu F1 cho 3 loại nhãn\n",
        "    labels_name = {1: \"Ki-67(+)\", 2: \"Ki-67(-)\", 3: \"TILs\"}\n",
        "\n",
        "    print(f\"--- Đang phân tích độ chính xác trên {min(num_samples, len(images))} mẫu test ---\")\n",
        "\n",
        "    for filename in images[:num_samples]:\n",
        "        json_path = os.path.join(folder_path, filename.replace('.jpg', '.json'))\n",
        "        if not os.path.exists(json_path): continue\n",
        "\n",
        "        # 1. Đọc nhãn chuẩn\n",
        "        with open(json_path, 'r') as f:\n",
        "            gt_data = json.load(f)\n",
        "\n",
        "        # 2. Dự đoán từ AI\n",
        "        img = imageio.imread(os.path.join(folder_path, filename))\n",
        "        img_input = np.expand_dims(img, axis=0) / 255.0\n",
        "        preds = model.predict(img_input, verbose=0)[0]\n",
        "\n",
        "        # 3. Tính toán cho từng loại tế bào\n",
        "        for l_id in [1, 2, 3]:\n",
        "            gt_coords = get_gt_by_label(gt_data, l_id)\n",
        "            # Lấy heatmap tương ứng kênh 0, 1, 2\n",
        "            pred_coords = peak_local_max(preds[:,:,l_id-1], min_distance=5, threshold_abs=0.1)\n",
        "\n",
        "            if len(gt_coords) > 0 and len(pred_coords) > 0:\n",
        "                dists = cdist(pred_coords, gt_coords)\n",
        "                matched_gt = set()\n",
        "                tp = 0\n",
        "                for i in range(len(pred_coords)):\n",
        "                    nearest = np.argmin(dists[i])\n",
        "                    if dists[i][nearest] < 15 and nearest not in matched_gt:\n",
        "                        tp += 1\n",
        "                        matched_gt.add(nearest)\n",
        "\n",
        "                pre = tp / len(pred_coords)\n",
        "                rec = tp / len(gt_coords)\n",
        "                f1 = 2 * pre * rec / (pre + rec) if (pre + rec) > 0 else 0\n",
        "                results[l_id].append({'f1': f1, 'pre': pre, 'rec': rec})\n",
        "\n",
        "    # In bảng kết quả tổng hợp\n",
        "    print(\"\\n\" + \"=\"*45)\n",
        "    print(f\"{'Loại tế bào':<15} | {'F1-Score':<10} | {'Precision':<10}\")\n",
        "    print(\"-\" * 45)\n",
        "    for l_id, metrics in results.items():\n",
        "        if metrics:\n",
        "            avg_f1 = np.mean([m['f1'] for m in metrics])\n",
        "            avg_pre = np.mean([m['pre'] for m in metrics])\n",
        "            print(f\"{labels_name[l_id]:<15} | {avg_f1:.4f}     | {avg_pre:.4f}\")\n",
        "    print(\"=\"*45)\n",
        "\n",
        "# Thực thi\n",
        "evaluate_accuracy(model, data_path)"
      ],
      "metadata": {
        "id": "KVy4tfbXsqqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}